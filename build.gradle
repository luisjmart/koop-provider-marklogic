buildscript {
    if (project.hasProperty("disconnected")) {
        dependencies {
            classpath fileTree(dir: "dependencies/buildscript", include: "*.jar")
        }
    }
    else {
        repositories {
            maven { url "https://plugins.gradle.org/m2/" }
            jcenter()
        }

        dependencies {
            classpath 'org.codehaus.groovy:groovy-json:2.4.15'
            classpath 'org.codehaus.groovy.modules.http-builder:http-builder:0.5.2'
            classpath "com.moowork.gradle:gradle-node-plugin:1.2.0"
            classpath "net.saliman:gradle-properties-plugin:1.4.6"
            classpath "com.marklogic:ml-gradle:3.12.0"
        }
    }
}

apply plugin: 'java'
apply plugin: 'net.saliman.properties'
apply plugin: "com.moowork.node"
apply plugin: "com.marklogic.ml-gradle"

ext {
    mlDeployerAppName = "MarkLogic-Esri-Connector"
    mlDeployerDir = "build/${mlDeployerAppName}"
    mlDeployerGroup = "ML Deployer"
    mlDeployerZipFilename = "${mlDeployerAppName}.zip"
}

/*
 * If the project has the "disconnected" property defined, then we look for mlcp dependencies in a directory
 * instead of retrieving them from a repository.
 */
if (project.hasProperty("disconnected") && disconnected) {
    println "\nRUNNING IN DISCONNECTED MODE"

    dependencies {
        compile fileTree(dir: "dependencies/buildscript", include: "*.jar")

        testImplementation fileTree(dir: "dependencies/testImplementation", include: "*.jar")
    }
}

/*
 * If we're not in disconnected mode, then we grab dependencies from repositories, and we define a set of tasks
 * for creating the "mlDeployer" zip file that can be used in a disconnected environment.
 */
else {
    repositories {
        maven { url "https://plugins.gradle.org/m2/" }
        maven { url "http://repository.cloudera.com/artifactory/cloudera-repos/" }
        maven { url "https://developer.marklogic.com/maven2/" }

        jcenter()
    }

    dependencies {
        testImplementation 'junit:junit:4.12'
        testImplementation 'io.rest-assured:rest-assured:3.0.6'
        testImplementation 'io.rest-assured:json-path:3.0.6'
        testImplementation "com.googlecode.json-simple:json-simple:1.1.1"
        testImplementation "org.gradle:gradle-tooling-api:2.1"
    }

    task copyProjectFiles(type: Copy, group: mlDeployerGroup) {
        dependsOn = [
            "installKoop",
            "buildPlugin"
	]

        from "."
        include "build.gradle", "gradle.properties", "gradle-example-app.properties", "gradle-example-connector.properties", "gradlew", "gradlew.bat"
        include "gradle/**"
        include "src/main/**"
        include "src/koop/**"
        include "src/example/**"
        include "build/koop/**"
        include "build/variancenativeplugin/**"
        include "log/**"
        include "data/example/**"
        include "config/example/**"
        into mlDeployerDir
    }

    task copyBuildScriptDependencies(type: Copy, group: mlDeployerGroup) {
        from buildscript.configurations.classpath
        into mlDeployerDir + "/dependencies/buildscript"
    }

    task addDisconnectedToGradleProperties {
        doLast {
            ant.propertyfile(file: "build/${mlDeployerAppName}/gradle.properties") {
                entry(key: "disconnected", value: "true")
            }
        }
    }

    addDisconnectedToGradleProperties.mustRunAfter copyProjectFiles

    task copyMlDeployerFiles(group: mlDeployerGroup) {
        dependsOn = [
            "copyProjectFiles",
            "copyBuildScriptDependencies",
            "addDisconnectedToGradleProperties"
        ]
    }

    task deleteMlDeployer(type: Delete, group: mlDeployerGroup) {
      delete mlDeployerDir, "build/${mlDeployerZipFilename}"
    }

    task buildMlDeployer (type: Zip, group: mlDeployerGroup) {
        description "Create a zip of this project's Gradle dependencies and source code so that it can be deployer without Internet access"
        dependsOn = ["deleteMlDeployer", "copyMlDeployerFiles"]
        from mlDeployerDir
        into mlDeployerAppName
        destinationDir file('build')
        archiveName mlDeployerZipFilename
    }

    copyMlDeployerFiles.mustRunAfter deleteMlDeployer
}

ext {
  mlAppConfig {
    if (project.hasProperty("mlSchemasDatabaseName")) {
      schemasDatabaseName = project.property("mlSchemasDatabaseName")
    }

    println "content database: " + contentDatabaseName
    println "schemas database: " + schemasDatabaseName
  }

  dmClient = com.marklogic.client.DatabaseClientFactory.newClient(
      mlHost, Integer.parseInt(mlRestPort),
      mlContentDatabaseName,
      new com.marklogic.client.DatabaseClientFactory.DigestAuthContext( mlUsername, mlPassword),
      com.marklogic.client.DatabaseClient.ConnectionType.GATEWAY
  );
}

test {
  doFirst {
    println "Running tests using the following properties:"
    println "host: " + mlHost
    println "port: " + koopPort
    println "user: " + mlUsername
  }

  systemProperty "featureServer.host", mlHost
  systemProperty "featureServer.port", koopPort
  systemProperty "featureServer.user", mlUsername
  systemProperty "featureServer.password", mlPassword
}

task installConnector(dependsOn: ['mlDeploy', 'installPlugin', 'configureKoop'])

task buildConnector(dependsOn: ['buildPlugin', 'installKoop'])

// Only build the plugin and install koop if we are not in disconnected mode
if (! project.hasProperty("disconnected") || ! disconnected) {
    installConnector.dependsOn("buildConnector")
    installConnector.mustRunAfter buildConnector
}

task installServices(dependsOn: [
    'loadFeatureServices',
    'loadSchemas',
    'loadQueryOptions',
    'loadQueryTransforms'
])

task buildPlugin(type: Exec) {
  doFirst {
    copy {
      from 'src/main/ml-native-plugins/variance'
      into 'build/variancenativeplugin'
    }
  }

  workingDir 'build/variancenativeplugin'
  commandLine 'make'
}
buildPlugin.onlyIf { !System.getProperty("os.name").toLowerCase().contains("windows") }

task installPlugin(dependsOn: [ 'mlDeploy' ], type: com.marklogic.gradle.task.MarkLogicTask) {
  doLast {
    // load binary to the modules database
    def client = newClient()

    def pluginZip = "build/variancenativeplugin/varianceplugin.zip"
    def pluginUri = "/native-plugins/varianceplugin.zip"

    def docMgr = client.newBinaryDocumentManager()
    docMgr.write(
      pluginUri,
      new com.marklogic.client.io.FileHandle().with(new File(pluginZip))
    )

    // eval xquery to install the plugin
    def query = '''
      xquery version "1.0-ml";
      import module namespace plugin = "http://marklogic.com/extension/plugin" at "MarkLogic/plugin/plugin.xqy";
      declare variable $plugin-uri as xs:string external;
      plugin:install-from-zip("native", fn:doc($plugin-uri)/node())
    '''
    def result = client.newServerEval()
      .xquery(query)
      .addVariable("plugin-uri", pluginUri)
      .evalAs(String.class)

    println "Installed " + result + " native plugin(s)"
  }
}
installPlugin.onlyIf { !System.getProperty("os.name").toLowerCase().contains("windows") }

node {
  // Base URL for fetching node distributions (change if you have a mirror).
  distBaseUrl = 'https://nodejs.org/dist'
  version = '8.11.4'

  // If true, it will download node using above parameters.
  // If false, it will try to use globally installed node.
  download = true

  // Set the work directory for unpacking node
  workDir = file("${project.buildDir}/koop/nodejs")

  // Set the work directory for NPM
  npmWorkDir = file("${project.buildDir}/koop/npm")
}

task configureKoop {
    outputs.upToDateWhen { false }
    doLast {
        copy {
            from("src/koop/config") {
                include "**"
                filter(org.apache.tools.ant.filters.ReplaceTokens, tokens: [
                        KOOP_PORT : project.property("koopPort"),
                        KOOP_SSL_ENABLED : project.property("koopSSLEnabled"),
                        KOOP_SSL_PORT : project.property("koopSSLPort"),
                        KOOP_SSL_CERT : project.property("koopSSLCert"),
                        KOOP_SSL_KEY : project.property("koopSSLKey"),
                        ML_HOST : mlAppConfig.host,
                        ML_PORT : mlAppConfig.restPort.toString(),
                        ML_USER : project.property("koopMlUsername"),
                        ML_PASSWORD : project.property("koopMlPassword")
                ])
            }

            into "build/koop/config"
        }
    }
}

task installKoop(type: NpmTask, dependsOn: ['configureKoop']) {
    doFirst {
        copy {
            from "src/koop"
            include "**"
            exclude "config"
            into "build/koop"
        }
    }

    args = ['install']
    workingDir = file('build/koop')
}

import groovy.json.JsonBuilder
import groovy.json.JsonOutput
import com.marklogic.client.io.DocumentMetadataHandle
import com.marklogic.client.io.DocumentMetadataHandle.Capability

task registerKoop(type: com.marklogic.gradle.task.MarkLogicTask) {
  doLast {
    def json = new JsonBuilder()
    def config = json {
      'host' project.findProperty('koopHost') ?: mlAppConfig.host
      'port' project.property('koopSSLEnabled').toBoolean() ? project.property('koopSSLPort') : project.property('koopPort')
      'ssl' project.property('koopSSLEnabled').toBoolean()
    }
    def docUri = '/koop/config.json'
    def client = newClient()
    def docManager = client.newJSONDocumentManager()
    def metadata = new DocumentMetadataHandle()
    metadata.getCollections().addAll('http://marklogic.com/koop-config')
    metadata.getPermissions().add('esri-connector-reader', Capability.READ)
    metadata.getPermissions().add('esri-connector-writer', Capability.UPDATE)
    docManager.writeAs(docUri, metadata, json.toString())

    println 'Registered the following Koop config into ML:'
    println 'uri: ' + docUri
    println 'doc: ' + JsonOutput.prettyPrint(json.toString())
  }
}

task runKoop(type: NodeTask, dependsOn: ['registerKoop']) {
  script = file('build/koop/server.js')
  execOverrides {
    it.workingDir = 'build/koop'

    //it.standardOutput = new FileOutputStream('logs/my.log')
  }

  environment = [
    'NODE_ENV': 'dev'
  ]
}

task fsConfigCheck() {
    doLast {
        if (! project.hasProperty("fsConfig")) throw new InvalidUserDataException("The fsConfig property is not set")
    }
}

task loadFeatureServices(type : com.marklogic.gradle.task.MarkLogicTask, dependsOn: [ "fsConfigCheck" ]) {
    doLast {
      def client = newClient()
      def metaHandle = new com.marklogic.client.io.DocumentMetadataHandle()
      metaHandle.withCollections("http://marklogic.com/feature-services")
      metaHandle.withPermission( "esri-connector-reader", com.marklogic.client.io.DocumentMetadataHandle.Capability.READ)
      metaHandle.withPermission( "esri-connector-writer", com.marklogic.client.io.DocumentMetadataHandle.Capability.UPDATE)
      metaHandle.withPermission( "esri-connector-admin", com.marklogic.client.io.DocumentMetadataHandle.Capability.UPDATE)
        
      def manager = client.newDocumentManager()

      try {
          fileTree( "config/${fsConfig}/services").visit { FileVisitDetails details ->
              def file = details.file
              def fileHandle = new com.marklogic.client.io.FileHandle(file)
              manager.write( "/${fsConfig}/services/" + file.getName(), metaHandle, fileHandle)
            
          }
        } 
        finally {
            client.release()
        }
    }
}


task loadSchemas(type: com.marklogic.gradle.task.schemas.LoadSchemasTask, dependsOn: ["fsConfigCheck"]) {
    doFirst {
        ext {
            mlAppConfig {
                schemasPath = "config/${fsConfig}/templates"
            }
        }
    }

    doLast {
        println "Schemas loaded"
    }
}

task loadQueryOptions(type : com.marklogic.gradle.task.MarkLogicTask, dependsOn: ["fsConfigCheck"]) {
  doLast {
    def client = newClient()
    def manager = client.newServerConfigManager().newQueryOptionsManager()

    if (file("config/${fsConfig}/options").exists()) {
        def files = files(file("config/${fsConfig}/options").listFiles())
        files.each { file ->
            def optionsName = file.name.substring(0, file.name.lastIndexOf("."))
            manager.writeOptions(
                optionsName, new com.marklogic.client.io.FileHandle().with(file)
            )
            println "Loaded query options: ${optionsName}"
        }
    }

    println "Query options loaded"
  }
}

task loadQueryTransforms(type : com.marklogic.gradle.task.MarkLogicTask, dependsOn: ["fsConfigCheck"]) {
  doLast {
    def client = newClient()
    def manager = client.newServerConfigManager().newTransformExtensionsManager()

    if (file("config/${fsConfig}/transforms").exists()) {
        def files = files(file("config/${fsConfig}/transforms").listFiles())
        files.each { file ->
            def transformName = file.name.substring(0, file.name.lastIndexOf("."))
            manager.writeXQueryTransform(
                transformName, new com.marklogic.client.io.FileHandle().with(file)
            )
            println "Loaded transform: ${transformName}"
        }
    }

    println "Query transforms loaded"
  }
}

task loadExampleData(dependsOn: [
  "loadGDeltExampleData",
  "loadZipCodeBoundaryExampleData"
])

task loadGDeltExampleData(type: com.marklogic.gradle.task.MarkLogicTask) {
  doLast {
    def client = newClient()
    def dmManager = client.newDataMovementManager();
    def batcher = 
      dmManager.newWriteBatcher()
        .withBatchSize(100)
        .withThreadCount(20)
        .onBatchSuccess( new com.marklogic.client.datamovement.WriteBatchListener() {
            void processEvent( com.marklogic.client.datamovement.WriteBatch batch) {
              println "batch # "+batch.getJobBatchNumber()+", so far: " + batch.getJobWritesSoFar();
            };
        })
        .onBatchFailure( new com.marklogic.client.datamovement.WriteFailureListener() {
            void processFailure( com.marklogic.client.datamovement.WriteBatch batch, java.lang.Throwable failure) {
              failure.printStackTrace();
            }
        });
    def ticket = dmManager.startJob(batcher);

    def metaHandle = new com.marklogic.client.io.DocumentMetadataHandle()
    metaHandle.withCollections("example-gkg")
    metaHandle.withPermission( "rest-reader", com.marklogic.client.io.DocumentMetadataHandle.Capability.READ)
    metaHandle.withPermission( "rest-writer", com.marklogic.client.io.DocumentMetadataHandle.Capability.UPDATE)

    if (file("data/example/gkg_geojson").exists()) {
        def files = files(file("data/example/gkg_geojson").listFiles())
        files.each { zipFile ->
          zipTree(zipFile).matching { exclude { FileTreeElement el -> el.directory } }.visit { element ->
            println "adding file: /gkg_geojson/${zipFile.name}/${element.relativePath}"
            batcher.add( "/gkg_geojson/${zipFile.name}/${element.relativePath}", metaHandle, new com.marklogic.client.io.FileHandle(element.file));
          } 
        }
    }
    
    batcher.flushAndWait();
    dmManager.stopJob(ticket);
    dmManager.release();

    println "GDeltExampleData loaded"

    def report = dmManager.getJobReport(ticket);

    println "SuccessBatches: " + report.getSuccessBatchesCount()
    println "SuccessEvents: " + report.getSuccessEventsCount()
    println "FailureBatches: " + report.getFailureBatchesCount()
    println "FailureEvents: " + report.getFailureEventsCount()
  }
}

task loadZipCodeBoundaryExampleData(type: com.marklogic.gradle.task.MarkLogicTask) {
  doLast {
    def client = newClient()
    def dmManager = client.newDataMovementManager();
    def batcher = 
      dmManager.newWriteBatcher()
        .withBatchSize(100)
        .withThreadCount(20)
        .onBatchSuccess( new com.marklogic.client.datamovement.WriteBatchListener() {
            void processEvent( com.marklogic.client.datamovement.WriteBatch batch) {
              println "batch # "+batch.getJobBatchNumber()+", so far: " + batch.getJobWritesSoFar();
            };
        })
        .onBatchFailure( new com.marklogic.client.datamovement.WriteFailureListener() {
            void processFailure( com.marklogic.client.datamovement.WriteBatch batch, java.lang.Throwable failure) {
              failure.printStackTrace();
            }
        });
    def ticket = dmManager.startJob(batcher);

    def metaHandle = new com.marklogic.client.io.DocumentMetadataHandle()
    metaHandle.withCollections("zipcodes","test-data")
    metaHandle.withPermission( "rest-reader", com.marklogic.client.io.DocumentMetadataHandle.Capability.READ)
    metaHandle.withPermission( "rest-writer", com.marklogic.client.io.DocumentMetadataHandle.Capability.UPDATE)

    if (file("data/example/zipcodes").exists()) {
        def files = files(file("data/example/zipcodes").listFiles())
        files.each { zipFile ->
          zipTree(zipFile).matching { exclude { FileTreeElement el -> el.directory } }.visit { element ->
            println "adding file: /zipcodes/${zipFile.name}/${element.relativePath}"
            batcher.add( "/zipcodes/${zipFile.name}/${element.relativePath}", metaHandle, new com.marklogic.client.io.FileHandle(element.file));
          } 
        }
    }
    
    batcher.flushAndWait();
    dmManager.stopJob(ticket);
    dmManager.release();

    println "ZipCodeBoundaryExampleData loaded"

    def report = dmManager.getJobReport(ticket);

    println "SuccessBatches: " + report.getSuccessBatchesCount()
    println "SuccessEvents: " + report.getSuccessEventsCount()
    println "FailureBatches: " + report.getFailureBatchesCount()
    println "FailureEvents: " + report.getFailureEventsCount()
  }
}


task loadTestData(dependsOn: [
  "loadGDeltTestData",
  "loadGeoLocationTestData"
])

task loadGDeltTestData(type: com.marklogic.gradle.task.MarkLogicTask) {
  doLast {
    def client = newClient()
    def dmManager = client.newDataMovementManager();
    def batcher = 
      dmManager.newWriteBatcher()
        .withBatchSize(100)
        .withThreadCount(20)
        .onBatchSuccess( new com.marklogic.client.datamovement.WriteBatchListener() {
            void processEvent( com.marklogic.client.datamovement.WriteBatch batch) {
              println "batch # "+batch.getJobBatchNumber()+", so far: " + batch.getJobWritesSoFar();
            };
        })
        .onBatchFailure( new com.marklogic.client.datamovement.WriteFailureListener() {
            void processFailure( com.marklogic.client.datamovement.WriteBatch batch, java.lang.Throwable failure) {
              failure.printStackTrace();
            }
        });
    def ticket = dmManager.startJob(batcher);

    def metaHandle = new com.marklogic.client.io.DocumentMetadataHandle()
    metaHandle.withCollections("example-gkg","test-data")
    metaHandle.withPermission( "rest-reader", com.marklogic.client.io.DocumentMetadataHandle.Capability.READ)
    metaHandle.withPermission( "rest-writer", com.marklogic.client.io.DocumentMetadataHandle.Capability.UPDATE)

    if (file("data/test/gkg_geojson").exists()) {
        def files = files(file("data/test/gkg_geojson").listFiles())
        files.each { zipFile ->
          zipTree(zipFile).matching { exclude { FileTreeElement el -> el.directory } }.visit { element ->
            println "adding file: /gkg_geojson/${zipFile.name}/${element.relativePath}"
            batcher.add( "/gkg_geojson/${zipFile.name}/${element.relativePath}", metaHandle, new com.marklogic.client.io.FileHandle(element.file));
          } 
        }
    }
    
    batcher.flushAndWait();
    dmManager.stopJob(ticket);
    dmManager.release();

    println "GDeltTestData loaded"

    def report = dmManager.getJobReport(ticket);

    println "SuccessBatches: " + report.getSuccessBatchesCount()
    println "SuccessEvents: " + report.getSuccessEventsCount()
    println "FailureBatches: " + report.getFailureBatchesCount()
    println "FailureEvents: " + report.getFailureEventsCount()
  }
}

task listFiles () {
  doLast {
    def files = files(file("data/test/gkg_geojson").listFiles())
    files.each { zipFile ->
      zipTree(zipFile).matching { exclude { FileTreeElement el -> el.directory } }.visit { element ->
        println zipFile.name + " " + element.relativePath
      } 
    }
  }
}

task loadGeoLocationTestData(type: com.marklogic.gradle.task.MarkLogicTask) {
  doLast {
    def client = newClient()
    def dmManager = client.newDataMovementManager();
    def batcher = 
      dmManager.newWriteBatcher()
        .withBatchSize(100)
        .withThreadCount(20)
        .onBatchSuccess( new com.marklogic.client.datamovement.WriteBatchListener() {
            void processEvent( com.marklogic.client.datamovement.WriteBatch batch) {
              println "batch # "+batch.getJobBatchNumber()+", so far: " + batch.getJobWritesSoFar();
            };
        })
        .onBatchFailure( new com.marklogic.client.datamovement.WriteFailureListener() {
            void processFailure( com.marklogic.client.datamovement.WriteBatch batch, java.lang.Throwable failure) {
              failure.printStackTrace();
            }
        });
    def ticket = dmManager.startJob(batcher);

    def metaHandle = new com.marklogic.client.io.DocumentMetadataHandle()
    metaHandle.withCollections("example-geo","test-data")
    metaHandle.withPermission( "rest-reader", com.marklogic.client.io.DocumentMetadataHandle.Capability.READ)
    metaHandle.withPermission( "rest-writer", com.marklogic.client.io.DocumentMetadataHandle.Capability.UPDATE)

    if (file("data/test/GeoLocation").exists()) {
        def files = files(file("data/test/GeoLocation").listFiles())
        files.each { zipFile ->
          zipTree(zipFile).matching { exclude { FileTreeElement el -> el.directory } }.visit { element ->
            println "adding file: /GeoLocation/${zipFile.name}/${element.relativePath}"
            batcher.add( "/GeoLocation/${zipFile.name}/${element.relativePath}", metaHandle, new com.marklogic.client.io.FileHandle(element.file));
          } 
        }
    }
    
    batcher.flushAndWait();
    dmManager.stopJob(ticket);
    dmManager.release();

    println "GeoLocationTestData loaded"

    def report = dmManager.getJobReport(ticket);

    println "SuccessBatches: " + report.getSuccessBatchesCount()
    println "SuccessEvents: " + report.getSuccessEventsCount()
    println "FailureBatches: " + report.getFailureBatchesCount()
    println "FailureEvents: " + report.getFailureEventsCount()
  }
}

import groovyx.net.http.HTTPBuilder
import static groovyx.net.http.Method.POST
import static groovyx.net.http.ContentType.JSON

task testExampleService(type: com.marklogic.gradle.task.MarkLogicTask) {
  doLast {
    def config = getAppConfig()
    def url = 'http://' + config.getHost() + ':' + config.getRestPort() + '/LATEST/resources/KoopProvider'

    def http = new HTTPBuilder(url)
    http.auth.basic config.getRestAdminUsername() , config.getRestAdminPassword()

    def response = http.request( POST, JSON ) { req ->
      body = [
        params : [
          id : "GDeltGKG",
          layer : 0,
          method : "query"
        ],
        query : [
          resultRecordCount : 5,
          outFields : "*"
        ]
      ]

      response.success = { resp, json ->
        println(json)
      }
    }
  }
}

// This task is used specifically for testing the roles assigned to the Service Descriptors.
// We could do this in the test, but copying files with filtering is MUCH cleaner in Groovy.
task configureUnauthorizedKoop {
    outputs.upToDateWhen { false }
    doLast {
        copy {
            from("src/koop/config") {
                include "**"
                filter(org.apache.tools.ant.filters.ReplaceTokens, tokens: [
                        KOOP_PORT : project.property("koopUnauthorizedPort"),
                        KOOP_SSL_ENABLED : project.property("koopSSLEnabled"),
                        KOOP_SSL_PORT : project.property("koopSSLPort"),
                        KOOP_SSL_CERT : project.property("koopSSLCert"),
                        KOOP_SSL_KEY : project.property("koopSSLKey"),
                        ML_HOST : mlAppConfig.host,
                        ML_PORT : mlAppConfig.restPort.toString(),
                        ML_USER : project.property("koopUnauthorizedMlUsername"),
                        ML_PASSWORD : project.property("koopUnauthorizedMlPassword")
                ])
            }

            into "build/koop/config"
        }
    }
}
